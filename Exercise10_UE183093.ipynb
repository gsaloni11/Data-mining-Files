{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from itertools import chain, combinations\n",
    "from collections import defaultdict\n",
    "from optparse import OptionParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsets(arr):\n",
    "    \"\"\" Returns non empty subsets of arr\"\"\"\n",
    "    return chain(*[combinations(arr, i + 1) for i, a in enumerate(arr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnItemsWithMinSupport(itemSet, transactionList, minSupport, freqSet):\n",
    "    \"\"\"calculates the support for items in the itemSet and returns a subset\n",
    "    of the itemSet each of whose elements satisfies the minimum support\"\"\"\n",
    "    _itemSet = set()\n",
    "    localSet = defaultdict(int)\n",
    "\n",
    "    for item in itemSet:\n",
    "        for transaction in transactionList:\n",
    "            if item.issubset(transaction):\n",
    "                freqSet[item] += 1\n",
    "                localSet[item] += 1\n",
    "\n",
    "    for item, count in localSet.items():\n",
    "        support = float(count) / len(transactionList)\n",
    "\n",
    "        if support >= minSupport:\n",
    "            _itemSet.add(item)\n",
    "\n",
    "    return _itemSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinSet(itemSet, length):\n",
    "    \"\"\"Join a set with itself and returns the n-element itemsets\"\"\"\n",
    "    return set(\n",
    "        [i.union(j) for i in itemSet for j in itemSet if len(i.union(j)) == length]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getItemSetTransactionList(data_iterator):\n",
    "    transactionList = list()\n",
    "    itemSet = set()\n",
    "    for record in data_iterator:\n",
    "        transaction = frozenset(record)\n",
    "        transactionList.append(transaction)\n",
    "        for item in transaction:\n",
    "            itemSet.add(frozenset([item]))  # Generate 1-itemSets\n",
    "    return itemSet, transactionList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runApriori(data_iter, minSupport, minConfidence):\n",
    "    \"\"\"\n",
    "    run the apriori algorithm. data_iter is a record iterator\n",
    "    Return both:\n",
    "     - items (tuple, support)\n",
    "     - rules ((pretuple, posttuple), confidence)\n",
    "    \"\"\"\n",
    "    itemSet, transactionList = getItemSetTransactionList(data_iter)\n",
    "\n",
    "    freqSet = defaultdict(int)\n",
    "    largeSet = dict()\n",
    "    # Global dictionary which stores (key=n-itemSets,value=support)\n",
    "    # which satisfy minSupport\n",
    "\n",
    "    assocRules = dict()\n",
    "    # Dictionary which stores Association Rules\n",
    "\n",
    "    oneCSet = returnItemsWithMinSupport(itemSet, transactionList, minSupport, freqSet)\n",
    "\n",
    "    currentLSet = oneCSet\n",
    "    k = 2\n",
    "    while currentLSet != set([]):\n",
    "        largeSet[k - 1] = currentLSet\n",
    "        currentLSet = joinSet(currentLSet, k)\n",
    "        currentCSet = returnItemsWithMinSupport(\n",
    "            currentLSet, transactionList, minSupport, freqSet\n",
    "        )\n",
    "        currentLSet = currentCSet\n",
    "        k = k + 1\n",
    "    def getSupport(item):\n",
    "        \"\"\"local function which Returns the support of an item\"\"\"\n",
    "        return float(freqSet[item]) / len(transactionList)\n",
    "\n",
    "    toRetItems = []\n",
    "    for key, value in largeSet.items():\n",
    "        toRetItems.extend([(tuple(item), getSupport(item)) for item in value])\n",
    "\n",
    "    toRetRules = []\n",
    "    for key, value in list(largeSet.items())[1:]:\n",
    "        for item in value:\n",
    "            _subsets = map(frozenset, [x for x in subsets(item)])\n",
    "            for element in _subsets:\n",
    "                remain = item.difference(element)\n",
    "                if len(remain) > 0:\n",
    "                    confidence = getSupport(item) / getSupport(element)\n",
    "                    if confidence >= minConfidence:\n",
    "                        toRetRules.append(((tuple(element), tuple(remain)), confidence))\n",
    "    return toRetItems, toRetRules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResults(items, rules):\n",
    "    \"\"\"prints the generated itemsets sorted by support and the confidence rules sorted by confidence\"\"\"\n",
    "    for item, support in sorted(items, key=lambda x: x[1]):\n",
    "        print(\"item: %s , %.3f\" % (str(item), support))\n",
    "    print(\"\\n------------------------ RULES:\")\n",
    "    for rule, confidence in sorted(rules, key=lambda x: x[1]):\n",
    "        pre, post = rule\n",
    "        print(\"Rule: %s ==> %s , %.3f\" % (str(pre), str(post), confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str_results(items, rules):\n",
    "    \"\"\"prints the generated itemsets sorted by support and the confidence rules sorted by confidence\"\"\"\n",
    "    i, r = [], []\n",
    "    for item, support in sorted(items, key=lambda x: x[1]):\n",
    "        x = \"item: %s , %.3f\" % (str(item), support)\n",
    "        i.append(x)\n",
    "\n",
    "    for rule, confidence in sorted(rules, key=lambda x: x[1]):\n",
    "        pre, post = rule\n",
    "        x = \"Rule: %s ==> %s , %.3f\" % (str(pre), str(post), confidence)\n",
    "        r.append(x)\n",
    "\n",
    "    return i, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataFromFile(fname):\n",
    "    \"\"\"Function which reads from the file and yields a generator\"\"\"\n",
    "    with open(fname, \"rU\") as file_iter:\n",
    "        for line in file_iter:\n",
    "            line = line.strip().rstrip(\",\")  # Remove trailing comma\n",
    "            record = frozenset(line.split(\",\"))\n",
    "            yield record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item: ('Brooklyn',) , 0.152\n",
      "item: ('HISPANIC',) , 0.164\n",
      "item: ('HISPANIC', 'MBE') , 0.164\n",
      "item: ('WBE', 'MBE') , 0.169\n",
      "item: ('New York', 'MBE') , 0.170\n",
      "item: ('New York', 'WBE') , 0.175\n",
      "item: ('ASIAN', 'MBE') , 0.200\n",
      "item: ('ASIAN',) , 0.202\n",
      "item: ('New York',) , 0.295\n",
      "item: ('NON-MINORITY',) , 0.300\n",
      "item: ('NON-MINORITY', 'WBE') , 0.300\n",
      "item: ('BLACK',) , 0.301\n",
      "item: ('MBE', 'BLACK') , 0.301\n",
      "item: ('WBE',) , 0.477\n",
      "item: ('MBE',) , 0.671\n",
      "\n",
      "------------------------ RULES:\n",
      "Rule: ('New York',) ==> ('MBE',) , 0.578\n",
      "Rule: ('New York',) ==> ('WBE',) , 0.594\n",
      "Rule: ('WBE',) ==> ('NON-MINORITY',) , 0.628\n",
      "Rule: ('ASIAN',) ==> ('MBE',) , 0.990\n",
      "Rule: ('BLACK',) ==> ('MBE',) , 1.000\n",
      "Rule: ('NON-MINORITY',) ==> ('WBE',) , 1.000\n",
      "Rule: ('HISPANIC',) ==> ('MBE',) , 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-0d2158b66983>:3: DeprecationWarning: 'U' mode is deprecated\n",
      "  with open(fname, \"rU\") as file_iter:\n"
     ]
    }
   ],
   "source": [
    "inFile=dataFromFile('basket.csv')\n",
    "minSupport = 0.15\n",
    "minConfidence = 0.5\n",
    "\n",
    "items, rules = runApriori(inFile, minSupport, minConfidence)\n",
    "\n",
    "printResults(items, rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item: ('NON-MINORITY',) , 0.300\n",
      "item: ('NON-MINORITY', 'WBE') , 0.300\n",
      "item: ('BLACK',) , 0.301\n",
      "item: ('MBE', 'BLACK') , 0.301\n",
      "item: ('WBE',) , 0.477\n",
      "item: ('MBE',) , 0.671\n",
      "\n",
      "------------------------ RULES:\n",
      "Rule: ('WBE',) ==> ('NON-MINORITY',) , 0.628\n",
      "Rule: ('NON-MINORITY',) ==> ('WBE',) , 1.000\n",
      "Rule: ('BLACK',) ==> ('MBE',) , 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-0d2158b66983>:3: DeprecationWarning: 'U' mode is deprecated\n",
      "  with open(fname, \"rU\") as file_iter:\n"
     ]
    }
   ],
   "source": [
    "inFile=dataFromFile('basket.csv')\n",
    "minSupport = 0.3\n",
    "minConfidence = 0.5\n",
    "\n",
    "items, rules = runApriori(inFile, minSupport, minConfidence)\n",
    "\n",
    "printResults(items, rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item: ('Brooklyn',) , 0.152\n",
      "item: ('HISPANIC',) , 0.164\n",
      "item: ('HISPANIC', 'MBE') , 0.164\n",
      "item: ('WBE', 'MBE') , 0.169\n",
      "item: ('New York', 'MBE') , 0.170\n",
      "item: ('New York', 'WBE') , 0.175\n",
      "item: ('ASIAN', 'MBE') , 0.200\n",
      "item: ('ASIAN',) , 0.202\n",
      "item: ('New York',) , 0.295\n",
      "item: ('NON-MINORITY',) , 0.300\n",
      "item: ('NON-MINORITY', 'WBE') , 0.300\n",
      "item: ('BLACK',) , 0.301\n",
      "item: ('MBE', 'BLACK') , 0.301\n",
      "item: ('WBE',) , 0.477\n",
      "item: ('MBE',) , 0.671\n",
      "\n",
      "------------------------ RULES:\n",
      "Rule: ('WBE',) ==> ('MBE',) , 0.354\n",
      "Rule: ('WBE',) ==> ('New York',) , 0.367\n",
      "Rule: ('MBE',) ==> ('BLACK',) , 0.448\n",
      "Rule: ('New York',) ==> ('MBE',) , 0.578\n",
      "Rule: ('New York',) ==> ('WBE',) , 0.594\n",
      "Rule: ('WBE',) ==> ('NON-MINORITY',) , 0.628\n",
      "Rule: ('ASIAN',) ==> ('MBE',) , 0.990\n",
      "Rule: ('BLACK',) ==> ('MBE',) , 1.000\n",
      "Rule: ('NON-MINORITY',) ==> ('WBE',) , 1.000\n",
      "Rule: ('HISPANIC',) ==> ('MBE',) , 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-0d2158b66983>:3: DeprecationWarning: 'U' mode is deprecated\n",
      "  with open(fname, \"rU\") as file_iter:\n"
     ]
    }
   ],
   "source": [
    "inFile=dataFromFile('basket.csv')\n",
    "minSupport = 0.15\n",
    "minConfidence = 0.3\n",
    "\n",
    "items, rules = runApriori(inFile, minSupport, minConfidence)\n",
    "\n",
    "printResults(items, rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item: ('MBE',) , 0.671\n",
      "\n",
      "------------------------ RULES:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-0d2158b66983>:3: DeprecationWarning: 'U' mode is deprecated\n",
      "  with open(fname, \"rU\") as file_iter:\n"
     ]
    }
   ],
   "source": [
    "inFile=dataFromFile('basket.csv')\n",
    "minSupport = 0.6\n",
    "minConfidence = 0.25\n",
    "\n",
    "items, rules = runApriori(inFile, minSupport, minConfidence)\n",
    "\n",
    "printResults(items, rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-0d2158b66983>:3: DeprecationWarning: 'U' mode is deprecated\n",
      "  with open(fname, \"rU\") as file_iter:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Number Of Rules Are: \n",
      "74\n",
      "Confidence Values where number of rules are minimum i.e. 0\n",
      "Support Values\tConfidence Values\n",
      "0.35 :\t\t {0.35}\n",
      "0.4 :\t\t {0.4}\n",
      "0.45 :\t\t {0.45}\n",
      "0.5 :\t\t {0.5}\n",
      "0.55 :\t\t {0.55}\n",
      "0.6 :\t\t {0.6}\n",
      "0.65 :\t\t {0.65}\n",
      "0.7 :\t\t {0.7}\n",
      "0.75 :\t\t {0.75}\n",
      "0.8 :\t\t {0.8}\n",
      "0.85 :\t\t {0.85}\n",
      "0.9 :\t\t {0.9}\n",
      "0.95 :\t\t {0.95}\n"
     ]
    }
   ],
   "source": [
    "minSupport = 0.05\n",
    "minConfidence = 0\n",
    "Rules_max = 0\n",
    "SupportValues=defaultdict(set)\n",
    "\n",
    "while minSupport <= 1:\n",
    "    minConfidence = 0.05\n",
    "    while minConfidence <= 1:\n",
    "        inFile=dataFromFile('basket.csv')\n",
    "        items, rules = runApriori(inFile, minSupport, minConfidence)\n",
    "        Rules_max = max(Rules_max, len(rules))\n",
    "        if len(rules) == 0:\n",
    "            SupportValues[round(minSupport,2)].add(round(minConfidence,2))\n",
    "        minConfidence += 0.05\n",
    "        minSupport += 0.05\n",
    "\n",
    "print(\"Maximum Number Of Rules Are: \")\n",
    "print(Rules_max)\n",
    "print(\"Confidence Values where number of rules are minimum i.e. 0\")\n",
    "\n",
    "print(\"Support Values\\tConfidence Values\")\n",
    "for i in SupportValues.keys():\n",
    "    print(str(i)+\" :\\t\\t\",SupportValues[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
